---
title: xielinxi：视觉识别领域发展的观点
description: 从人人信任出发来探究人机信任
tags: [Visual]
categories:
 - article
comment_title: xielinxi：视觉识别领域发展的观点
---

[原文](https://zhuanlan.zhihu.com/p/558646681?utm_medium=social&utm_oi=788544272327643136&utm_psn=1547372044911783936&utm_source=wechat_session&utm_id=0&s_r=0)

图像信号的三个根本性质：

信息稀疏， 域间差异， 无限粒度

CV三大基本困难：

1、**语义稀疏性**

2、在采样不同域（即不同分布，如白天和黑夜、晴天和雨天等场景）时，采样结果（即图像像素）与域特性强相关，导致了**域间差异性**

3、图像的基本语义单元很难定义：**无限粒度性**

语义稀疏性：解决方案为**构建高效计算模型（神经网络）**和**视觉预训练**。最为高效的建模方式有两类，一类是通过神经网络架构设计，来捕捉**数据无关**的先验分布，一类是通过在大规模数据上的预训练，来捕捉**数据相关**的先验分布。

域间差异性：解决方案为**数据高效的微调算法**。根据以上分析，网络体量越大、预训练数据集体量越大，计算模型中存储的先验就越强。考虑到目标域的数据体量往往远小于预训练域，因而**数据高效**是必不可少的假设。此外，从实用的角度看，模型必须能够适应随时变化的域，因而**终身学习**是必须。

无限粒度性：解决方案为**开放域识别算法**。无限粒度性包含开放域特性，是更高的追求目标。随着跨模态预训练方法的涌现（特别是2021年的CLIP），自然语言越来越接近成为开放域识别的牵引器。

> 作者：然而，我并不赞成在追求开放域识别的过程中，涌现出的各种zero-shot识别任务。我认为zero-shot本身是一个伪命题，世界上并不存在也不需要zero-shot识别方法。现有的zero-shot任务，都是使用不同方法，将信息泄露给算法，而泄露方式的千差万别，导致不同方法之间难以进行公平对比。

需要考虑域迁移，而域迁移的核心在于避免过拟合



### Solution：

#### 方向1a: 网络架构设计（卷积、transformer）

> 如果一定要在卷积和transformer之间做取舍，那么transformer的潜力更大，主要因为它能够统一不同的数据模态，尤其是文本和图像这两个最常见也最重要的模态。

#### 方向1b:视觉预训练

- 有监督

- 无监督

  > MIM：Masked Image Modeling

- 跨模态预训练

  它使用弱配对的图像和文本作为训练素材，一方面避免了图像监督信号带来的bias，一方面又比无监督方法更能学习弱语义。此外，在transformer的加持下，视觉和自然语言的融合也更自然、更合理。



#### **方向2：模型微调和终身学习**

迁移学习：假设 Dpre 或者 Dtrain 和 Dtest 的数据分布大不相同；

弱监督学习：假设 Dtrain 只提供了不完整的标注信息；

半监督学习：假设 Dtrain 只有部分数据被标注；

带噪学习：假设 Dtrain 的部分数据标注可能有误；

主动学习：假设 Dtrain 可以通过交互形式标注（挑选其中最难的样本）以提升标注效率；

持续学习：假设不断有新的 Dtrain 出现，从而学习过程中可能会遗忘从 Dpre 学习的内容；



> 我们不追求AI能自主解决所有问题，但是AI算法应该有一个规范操作流程，让不懂AI的人能够遵循这个流程，新增他们想要的需求、解决平时遇到的问题，这样才能让AI真正平民化，解决实际问题。
>
> 对于学术界，必须尽快定义出符合真实场景的终身学习setting，建立起相应的benchmark，推动这一方向的研究



#### **方向3：无限细粒度视觉识别任务**

要达到无限细粒度的目标，必须满足以下三个条件。

- 开放性：开放域识别，是无限细粒度识别的一个子目标。目前看，引入语言是实现开放性的最佳方案之一。
- 特异性：引入语言时，不应被语言束缚，而应当设计视觉友好的指代方案（即识别任务）。
- 可变粒度性：并非总是要求识别到最细粒度，而是可以根据需求，灵活地改变识别的粒度。